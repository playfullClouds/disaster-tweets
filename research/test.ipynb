{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title | Classification of Crisis-related Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social media has emerged as an invaluable resource for humanitarian aid organizations to get real-time information about the situation on the ground\n",
    "during a natural disaster. Microblogging platforms like Twitter allow individuals to easily and quickly relay information on location, time, damage severity, etc. to the public at large. With a clearer understanding of what is happening at a micro-level, humanitarian aid organizations can more efficiently allocate and dispatch assistance, as well as inform victims about where and how to seek help. \n",
    "\n",
    "**While social media has the advantage of real-time information transmission during a fast-changing crisis, the sudden flood of posts and messages can easily overwhelm humanitarian organizations hoping to act on critical and relevant information.** Not all posts and messages tied to a disaster-related event are informative and useful to these organizations.\n",
    "\n",
    "**Machine Learning models can help play a role in the task of sifting through the deluge of disaster-related posts and identify which posts are the most informative for humanitarian aid purposes.**\n",
    "\n",
    "This project will compare **three classification machine learning models** (**Multinomial Naive-Bayes**, **CatBoostClassifier**, **LogisticRegression**, **RandomForestClassifier**, **XGBoost**, **GradientBoostingClassifier** and **K-Nearest Neighbors**) on this task and propose which model could perform the most effectively during a diaster-related event. For our models, we will train and test them on tweets that have been gathered from 7 natural disasters occurring during 2017: Hurricanes Irma, Harvey, and Maria; Earthquakes in Mexico and Iran & Iraq; Wildfires in California; and Floods in Sri Lanka.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Objective:**\n",
    "\n",
    "To accurately classify tweets related to natural disasters as informative or not informative, thereby enhancing the ability of humanitarian organizations to quickly identify and utilize valuable information for disaster response and relief efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this project comes from the **CrisisMMD (Crisis Multi-Modal Dataset)** https://crisisnlp.qcri.org/crisismmd, a collection gathered and made available by the **Crisis Computing team** at **Qatar Computing Research Institute (QCRI)** of **Hamad Bin Khalifa University (HBKU)**. \n",
    "\n",
    "Within this dataset are thousands of **tweets** sampled from over 14 million tweets collected during **seven major disasters** (earthquakes, floods, hurricanes, and wildfires) occurring in **2017** in various parts of the world (United States, Puerto Rico, Mexico, Sri Lanka, Iran and Iraq): **Hurricane Irma, Hurricane Harvey, Hurricane Maria, California wildfires, Mexico earthquake, Iran-Iraq earthquake, **and the** Sri Lanka floods**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets have been manually annotated with three types of labels.\n",
    "\n",
    "1. **Informative vs Not informative** (Text and Image)\n",
    "    - Informative\n",
    "    - Not informative\n",
    "\n",
    "2. **Humanitarian Categories** (Text and Image)\n",
    "    - Affected individuals\n",
    "    - Infrastructure and utility damage\n",
    "    - Injured or dead people\n",
    "    - Missing or found people\n",
    "    - Rescue, volunteering or donation effort\n",
    "    - Vehicle damage\n",
    "    - Other relevant information\n",
    "    - Not humanitarian\n",
    "    \n",
    "3. **Damage Severity Assessment** (Image)\n",
    "    - Severe damage\n",
    "    - Mild damage\n",
    "    - Little or no damage\n",
    "    - Don't know or can't judge\n",
    "    \n",
    "However, for this project our focus will only be textual analysis and only focus on the labels for **Informative vs. Not informative**. We will discard image-related data as well as the labels for **Humanitarian Categoreis** and **Damage Severity Assessment**. \n",
    "\n",
    "The label **Informative vs. Not informative** indicates whether or not the text of the tweet is useful for humanitarian aid purposes.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will load every libraries that I am going to use throughout this project. I will group the libraries by their use. This will make it easier to read for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-03 22:04:07,772] 350 - matplotlib - DEBUG - __init__ - matplotlib data path: c:\\disaster-tweets\\dis\\Lib\\site-packages\\matplotlib\\mpl-data\n",
      "[2024-06-03 22:04:07,780] 350 - matplotlib - DEBUG - __init__ - CONFIGDIR=C:\\Users\\harry\\.matplotlib\n",
      "[2024-06-03 22:04:07,783] 1511 - matplotlib - DEBUG - __init__ - interactive is False\n",
      "[2024-06-03 22:04:07,783] 1512 - matplotlib - DEBUG - __init__ - platform is win32\n",
      "[2024-06-03 22:04:07,882] 350 - matplotlib - DEBUG - __init__ - CACHEDIR=C:\\Users\\harry\\.matplotlib\n",
      "[2024-06-03 22:04:07,890] 1574 - matplotlib.font_manager - DEBUG - font_manager - Using fontManager instance from C:\\Users\\harry\\.matplotlib\\fontlist-v330.json\n"
     ]
    }
   ],
   "source": [
    "# basic libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# libraries for data ingestion\n",
    "import zipfile\n",
    "import requests\n",
    "import traceback\n",
    "import urllib.request as request\n",
    "\n",
    "\n",
    "# Libraries for cleaning.\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from autocorrect import Speller\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('all', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# python dataclass decorator\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "# custom functions\n",
    "from src.logger import log\n",
    "from src.exception import CustomException\n",
    "from src.utils import unzip_data, download_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the URL of the source data to be downloaded\n",
    "\n",
    "# URL of the source data to be downloaded\n",
    "source_url: str = \"https://github.com/xplict33/mlproject/raw/main/data.zip\"\n",
    "\n",
    "# Path to the downloaded zip file\n",
    "zip_dir = \"data.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Download the dataset\n",
    "\n",
    "response = requests.get(source_url)\n",
    "with open(zip_dir, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "print(f\"Downloaded file to {zip_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Extract the dataset\n",
    "\n",
    "extracted_dir = 'data'\n",
    "with zipfile.ZipFile(zip_dir, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_dir)\n",
    "print(f\"Unzipped file to {extracted_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: List the files in the extracted directory\n",
    "\n",
    "extracted_files = os.listdir(extracted_dir)\n",
    "print(f\"Files in the extracted directory: {extracted_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>text_info</th>\n",
       "      <th>text_info_conf</th>\n",
       "      <th>image_info</th>\n",
       "      <th>image_info_conf</th>\n",
       "      <th>text_human</th>\n",
       "      <th>text_human_conf</th>\n",
       "      <th>image_human</th>\n",
       "      <th>image_human_conf</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>image_url</th>\n",
       "      <th>image_path</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>917791044158185473</td>\n",
       "      <td>917791044158185473_0</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.6766</td>\n",
       "      <td>other_relevant_information</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>other_relevant_information</td>\n",
       "      <td>0.6766</td>\n",
       "      <td>RT @Gizmodo: Wildfires raging through Northern...</td>\n",
       "      <td>http://pbs.twimg.com/media/DLyi_WYVYAApwNg.jpg</td>\n",
       "      <td>data_image/california_wildfires/10_10_2017/917...</td>\n",
       "      <td>gi ##z ##mo ##do wild ##fire rage northern cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>917791130590183424</td>\n",
       "      <td>917791130590183424_0</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>infrastructure_and_utility_damage</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>affected_individuals</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>PHOTOS: Deadly wildfires rage in California ht...</td>\n",
       "      <td>http://pbs.twimg.com/media/DLymKm9UMAAu0qw.jpg</td>\n",
       "      <td>data_image/california_wildfires/10_10_2017/917...</td>\n",
       "      <td>photo deadli wild ##fire rage california ##tc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>917791291823591425</td>\n",
       "      <td>917791291823591425_0</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>other_relevant_information</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>infrastructure_and_utility_damage</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...</td>\n",
       "      <td>http://pbs.twimg.com/media/DLudaaZV4AAjT7x.jpg</td>\n",
       "      <td>data_image/california_wildfires/10_10_2017/917...</td>\n",
       "      <td>cano ## pl ## share captur wild ##fire respons...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id              image_id    text_info  text_info_conf  \\\n",
       "0  917791044158185473  917791044158185473_0  informative          1.0000   \n",
       "1  917791130590183424  917791130590183424_0  informative          1.0000   \n",
       "2  917791291823591425  917791291823591425_0  informative          0.6813   \n",
       "\n",
       "    image_info  image_info_conf                         text_human  \\\n",
       "0  informative           0.6766         other_relevant_information   \n",
       "1  informative           0.6667  infrastructure_and_utility_damage   \n",
       "2  informative           1.0000         other_relevant_information   \n",
       "\n",
       "   text_human_conf                        image_human  image_human_conf  \\\n",
       "0           1.0000         other_relevant_information            0.6766   \n",
       "1           1.0000               affected_individuals            0.6667   \n",
       "2           0.6813  infrastructure_and_utility_damage            1.0000   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  RT @Gizmodo: Wildfires raging through Northern...   \n",
       "1  PHOTOS: Deadly wildfires rage in California ht...   \n",
       "2  RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...   \n",
       "\n",
       "                                        image_url  \\\n",
       "0  http://pbs.twimg.com/media/DLyi_WYVYAApwNg.jpg   \n",
       "1  http://pbs.twimg.com/media/DLymKm9UMAAu0qw.jpg   \n",
       "2  http://pbs.twimg.com/media/DLudaaZV4AAjT7x.jpg   \n",
       "\n",
       "                                          image_path  \\\n",
       "0  data_image/california_wildfires/10_10_2017/917...   \n",
       "1  data_image/california_wildfires/10_10_2017/917...   \n",
       "2  data_image/california_wildfires/10_10_2017/917...   \n",
       "\n",
       "                                           cleanText  \n",
       "0  gi ##z ##mo ##do wild ##fire rage northern cal...  \n",
       "1  photo deadli wild ##fire rage california ##tc ...  \n",
       "2  cano ## pl ## share captur wild ##fire respons...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.read_csv(\"C:\\\\disaster-tweets\\\\artifacts\\\\data_cleaner\\\\cleaned_data.csv\")\n",
    "t.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
